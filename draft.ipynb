{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJpsbsIYmUTJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import torch.distributed as dist\n",
        "## Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, Subset , random_split\n",
        "import torchvision.models as models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"./data\"\n",
        "random.seed(42)\n",
        "#Device\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuNEHNZhoToH",
        "outputId": "ee70a905-3a1c-419a-ac96-5bbd352d6cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCOT4omCmdjw",
        "outputId": "735d51a9-4f82-4772-b38f-a128a5e744c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/My Drive/self_supervised_learning'\n",
        "os.chdir(project_path)\n",
        "\n",
        "print(\"Current directory:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNH6qhiVmrPO",
        "outputId": "704733c3-3aed-40b4-8429-0d36cad9ad3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/My Drive/self_supervised_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFZhoyblmUTM"
      },
      "outputs": [],
      "source": [
        "from files.models import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802q483jmUTN"
      },
      "source": [
        "#### Data Preparation : Partionning & preprocesing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrQug0BumUTO"
      },
      "source": [
        "## **MNIST**\n",
        "\n",
        " Let's start by downloading the **MNIST** dataset: a very common and large database of grayscale images showing handwritten digits ranging from 0 to 9. It comprises 60,000 training images and 10,000 testing images of size 28x28.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJPJwLufmUTO"
      },
      "outputs": [],
      "source": [
        "# Transform to normalized Tensors in the range [0,1]\n",
        "\n",
        "transform = T.Compose([T.Pad(2) #to cope with the assumption about the \"same number of input pixels per image\", we choose the input dimension of 32x32 for all datasets. We thus resize all images (originally 28x28) using the padding function \"Pad\" (add 0 to the borders).\n",
        "                       , T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWr4nLb6mUTO"
      },
      "outputs": [],
      "source": [
        "MNIST_train_dataset = MNIST(root=DATASET_PATH, train= True, download=True, transform=transform)\n",
        "MNIST_test_dataset = MNIST(root=DATASET_PATH, train= False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlDQVABwmUTP",
        "outputId": "ed694774-3183-40f6-acae-2087011154d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: ./data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Pad(padding=2, fill=0, padding_mode=constant)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.5,), std=(0.5,))\n",
              "            ),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: ./data\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Pad(padding=2, fill=0, padding_mode=constant)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.5,), std=(0.5,))\n",
              "            ))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "MNIST_train_dataset, MNIST_test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "4O4fQueNmUTP",
        "outputId": "00067662-0976-4e7f-e7b6-b861538fa653"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize some examples\n",
        "NUM_IMAGES = 12\n",
        "MNIST_images = torch.stack([MNIST_train_dataset[np.random.randint(len(MNIST_train_dataset))][0] for idx in range(NUM_IMAGES)], dim=0)\n",
        "img_grid = torchvision.utils.make_grid(MNIST_images, nrow=6, normalize=True, pad_value=0.9)\n",
        "img_grid = img_grid.permute(1, 2, 0)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Image examples of the MNIST dataset\")\n",
        "plt.imshow(img_grid)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WRLTdhdmUTQ",
        "outputId": "9accb23c-b036-40ad-aefc-4fe16434bed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Mean: -0.8086686134338379\n",
            "Batch Std: 0.5371983051300049\n",
            "Batch Min: -1.0\n",
            "Batch Max: 1.0\n"
          ]
        }
      ],
      "source": [
        "# use DataLoader to keep applied transformation when download the data..\n",
        "\n",
        "MNIST_train_loader = torch.utils.data.DataLoader(MNIST_train_dataset, batch_size=64, shuffle=True)\n",
        "MNIST_test_loader = torch.utils.data.DataLoader(MNIST_test_dataset, batch_size=64, shuffle=False)\n",
        "# help(MNIST_train_loader)\n",
        "#check stats :\n",
        "data_iter = iter(MNIST_train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "mean = images.mean()\n",
        "std = images.std()\n",
        "min_val = images.min()\n",
        "max_val = images.max()\n",
        "\n",
        "print(f'Batch Mean: {mean.item()}')\n",
        "print(f'Batch Std: {std.item()}')\n",
        "print(f'Batch Min: {min_val.item()}')\n",
        "print(f'Batch Max: {max_val.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-2zG81AmUTQ",
        "outputId": "f273172b-11e6-4200-f00e-ca1644bf08d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "train_images, train_labels = next(iter(MNIST_train_loader))\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B--kYbQsmUTQ"
      },
      "source": [
        "### Baseline Model Setup : extent with limited labeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dARBQn-gmUTQ"
      },
      "outputs": [],
      "source": [
        "indices = np.random.permutation(len(MNIST_train_dataset))[:100]\n",
        "train_100= Subset(MNIST_train_dataset, indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_100_loader = DataLoader(train_100, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "TWwrPfZVxUNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1McYye4mUTR",
        "outputId": "12c685c4-186e-4753-ceeb-11f2f587bd44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 32, 32]), 4)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "image, label = train_100[0]\n",
        "image.shape, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkUuSvKkmUTR"
      },
      "outputs": [],
      "source": [
        "model = Basic_CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moKDU3CfmUTR",
        "outputId": "5e6fc8a4-d97a-4948-deca-505fa39bdbe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.5011\n",
            "Epoch [2/10], Loss: 1.8189\n",
            "Epoch [3/10], Loss: 1.1825\n",
            "Epoch [4/10], Loss: 0.8045\n",
            "Epoch [5/10], Loss: 0.5511\n",
            "Epoch [6/10], Loss: 0.3787\n",
            "Epoch [7/10], Loss: 0.2660\n",
            "Epoch [8/10], Loss: 0.2021\n",
            "Epoch [9/10], Loss: 0.1603\n",
            "Epoch [10/10], Loss: 0.1175\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_100_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_100_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQcbGA0wmUTR",
        "outputId": "c937d5ef-b6f6-43ff-b5f4-f5fd34342503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set (10K): 77.47%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in MNIST_test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on the test set (10K): {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply MoCo :\n",
        "workflow : Self-Supervised Pretraining --> Supervised Fine-Tuning --> evaluation"
      ],
      "metadata": {
        "id": "y1l2J7YU58Pb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CWMXxyLmUTS"
      },
      "source": [
        "MoCo was implemented on RGB ImageNet data with and ResNet encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG1fv0_BmUTS"
      },
      "source": [
        "* modify MoCo loader to handle our data\n",
        "* configuration (explore light encoder beside resnet(mnist is too simple than imageNet))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/facebookresearch/moco.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtIYogVcnddU",
        "outputId": "dc4912c6-764a-45bf-9305-e108487e0ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'moco' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MoCo(nn.Module):\n",
        "    \"\"\"\n",
        "    Build a MoCo model with: a query encoder, a key encoder, and a queue.\n",
        "    https://arxiv.org/abs/1911.05722\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_encoder, dim=128, K=65536, m=0.999, T=0.07, mlp=False):\n",
        "        \"\"\"\n",
        "        dim: feature dimension (default: 128)\n",
        "        K: queue size; number of negative keys (default: 65536)\n",
        "        m: momentum of updating key encoder (default: 0.999)\n",
        "        T: softmax temperature (default: 0.07)\n",
        "        \"\"\"\n",
        "        super(MoCo, self).__init__()\n",
        "\n",
        "        self.K = K\n",
        "        self.m = m\n",
        "        self.T = T\n",
        "\n",
        "\n",
        "        self.encoder_q = base_encoder(num_classes=dim)\n",
        "        self.encoder_k = base_encoder(num_classes=dim)\n",
        "\n",
        "        if mlp:\n",
        "            dim_mlp = self.encoder_q.fc.weight.shape[1]\n",
        "            self.encoder_q.fc = nn.Sequential(\n",
        "                nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_q.fc\n",
        "            )\n",
        "            self.encoder_k.fc = nn.Sequential(\n",
        "                nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.encoder_k.fc\n",
        "            )\n",
        "\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data.copy_(param_q.data)\n",
        "            param_k.requires_grad = False\n",
        "\n",
        "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
        "        self.queue = F.normalize(self.queue, dim=0)\n",
        "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _momentum_update_key_encoder(self):\n",
        "        \"\"\"\n",
        "        Momentum update of the key encoder.\n",
        "        \"\"\"\n",
        "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
        "            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def _dequeue_and_enqueue(self, keys):\n",
        "        \"\"\"\n",
        "        Dequeue the oldest keys and enqueue the new ones.\n",
        "        \"\"\"\n",
        "        batch_size = keys.shape[0]\n",
        "\n",
        "        ptr = int(self.queue_ptr)\n",
        "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
        "        ptr = (ptr + batch_size) % self.K\n",
        "        self.queue_ptr[0] = ptr\n",
        "\n",
        "    def forward(self, im_q, im_k):\n",
        "        \"\"\"\n",
        "        Compute logits and labels for contrastive loss.\n",
        "        \"\"\"\n",
        "        q = self.encoder_q(im_q)\n",
        "        q = F.normalize(q, dim=1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self._momentum_update_key_encoder()\n",
        "            k = self.encoder_k(im_k)\n",
        "            k = F.normalize(k, dim=1)\n",
        "\n",
        "\n",
        "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
        "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
        "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
        "        logits /= self.T  #temperature scaling\n",
        "\n",
        "\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
        "\n",
        "\n",
        "        self._dequeue_and_enqueue(k)\n",
        "\n",
        "        return logits, labels\n"
      ],
      "metadata": {
        "id": "Xrp-N_N-0ceh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_encoder(num_classes):\n",
        "    model = models.resnet18(weights=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "9PlrypLf0lKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(os.path.abspath('./moco'))\n",
        "\n",
        "print(\"Python path:\", sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0HfhtkC1dJa",
        "outputId": "fc6126a2-3a9a-4d8f-9651-50403c9ff9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python path: ['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/usr/local/lib/python3.10/dist-packages/setuptools/_vendor', '/root/.ipython', '/tmp/tmp17_bihm3', '/content/drive/MyDrive/self_supervised_learning/moco', '/content/drive/MyDrive/self_supervised_learning/moco', '/content/drive/MyDrive/self_supervised_learning/moco/moco']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls moco\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZjaHR1Q1yrB",
        "outputId": "31a653ed-4447-4d47-eadb-e7c90d3be646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "builder.py  __init__.py  loader.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moco.moco.loader import TwoCropsTransform"
      ],
      "metadata": {
        "id": "rJKEpDU9oRZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moco_model = MoCo(base_encoder=simple_encoder, dim=128, K=4096, mlp=True)\n",
        "moco_model = moco_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy0dYKP62BV8",
        "outputId": "5fadcd7d-e105-4b3e-a03f-53c5cf4db8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "nb_workers = 2"
      ],
      "metadata": {
        "id": "tly3E29Uq3pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_transform = T.Compose([\n",
        "    T.Grayscale(num_output_channels=3),\n",
        "    T.RandomResizedCrop(128, scale=(0.2, 1.0)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# Apply TwoCropsTransform\n",
        "Moco_train_transform = TwoCropsTransform(base_transform)"
      ],
      "metadata": {
        "id": "1uHsjZzdqFh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_train_dataset = MNIST(root=DATASET_PATH, train=True, download=True, transform=Moco_train_transform)\n",
        "\n",
        "\n",
        "all_indices = np.arange(len(MNIST_train_dataset))\n",
        "rest_indices = np.setdiff1d(all_indices, indices) #indices are the 100 indices labeled\n",
        "train_unlabeled = Subset(MNIST_train_dataset, rest_indices)\n",
        "\n",
        "train_loader = DataLoader(train_unlabeled, batch_size=batch_size, shuffle=True, num_workers=nb_workers, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "7RmpqW7jqmDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    for images, _ in train_loader:\n",
        "        # images is a batch of lists, where each list contains [q, k]\n",
        "        im_q = torch.stack([x[0] for x in images]).cuda()  # Stack and move to GPU\n",
        "        im_k = torch.stack([x[1] for x in images]).cuda()\n",
        "\n",
        "        logits, labels = moco_model(im_q, im_k)\n",
        "\n",
        "        # contrastive loss\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEE-F6j32ONB",
        "outputId": "e804ea22-eca9-4b14-dc33-2b758347cc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 8.649298667907715\n",
            "Epoch 2, Loss: 8.253222465515137\n",
            "Epoch 3, Loss: 8.280200004577637\n",
            "Epoch 4, Loss: 8.502165794372559\n",
            "Epoch 5, Loss: 8.298921585083008\n",
            "Epoch 6, Loss: 8.337882995605469\n",
            "Epoch 7, Loss: 8.362114906311035\n",
            "Epoch 8, Loss: 8.334863662719727\n",
            "Epoch 9, Loss: 8.432254791259766\n",
            "Epoch 10, Loss: 8.298063278198242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(moco_model, \"/content/drive/My Drive/self_supervised_learning/trained_models/moco_model_10.pth\")\n",
        "# torch.save(moco_model.state_dict(), \"/content/drive/My Drive/self_supervised_learning/trained_models/moco_state_dict_10.pth\")\n",
        "# torch.save({\n",
        "# 'epoch': 10,\n",
        "# 'model_state_dict': moco_model.state_dict(),\n",
        "# 'optimizer_state_dict': optimizer.state_dict(),\n",
        "# }, \"/content/drive/My Drive/self_supervised_learning/trained_models/moco_checkpoint_10.pth\")"
      ],
      "metadata": {
        "id": "Znj2-lrv3nnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "moco_model = torch.load(\"/content/drive/My Drive/self_supervised_learning/trained_models/moco_model_10.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIVLpS-KIwme",
        "outputId": "498ca6a0-f443-4264-c12c-631240b47454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-206-b2edf3aa5fc3>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  moco_model = torch.load(\"/content/drive/My Drive/self_supervised_learning/trained_models/moco_model_10.pth\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning : Use the 100 labeled samples to train a classification head on top of the pretrained MoCo encoder"
      ],
      "metadata": {
        "id": "xY77JWHD-bSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reloading data with a simple transform  fct  to fine-tune with consistency ..\n",
        "labeled_transform = T.Compose([\n",
        "    T.Grayscale(num_output_channels=3),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "\n",
        "MNIST_train_dataset = MNIST(root=DATASET_PATH, train=True, transform=labeled_transform)\n",
        "train_100 = Subset(MNIST_train_dataset, indices)\n",
        "train_100_loader = DataLoader(train_100, batch_size=10, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "diSYFWoH6i1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, _ in train_100_loader:\n",
        "    print(images.shape)\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWAp6AabLMFX",
        "outputId": "a4bc7f71-502f-4d26-f09b-f8247783af2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in moco_model.encoder_q.parameters():\n",
        "    param.requires_grad = False  # Keep the encoder frozen\n",
        "for param in moco_model.encoder_q.fc.parameters():\n",
        "    param.requires_grad = True  # Enable gradients for the classification head"
      ],
      "metadata": {
        "id": "5JPmt0q38je0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(moco_model.encoder_q.fc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LIz9cczI6or",
        "outputId": "5f621458-da9d-4b54-e944-37d9af13a299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# moco_model.encoder_q"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N9yTv2GcFoFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original_conv1 = moco_model.encoder_q.conv1\n",
        "# moco_model.encoder_q.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# moco_model.encoder_q.conv1.weight.data = original_conv1.weight.data.repeat(3, 1, 1, 1) / 3"
      ],
      "metadata": {
        "id": "BPZ6DnoAIK96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(moco_model.encoder_q.fc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evD2_CALL0F_",
        "outputId": "cb8ce966-14ff-4dfb-9033-911171206d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=512, out_features=128, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(moco_model.encoder_q.conv1)\n",
        "print(moco_model.encoder_q.bn1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oct7ILT5L3Lq",
        "outputId": "80d9afb2-216d-4d8d-ad52-27d852bd7544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "moco_model.encoder_q = moco_model.encoder_q.cuda()\n"
      ],
      "metadata": {
        "id": "fb0azk0GM3fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(moco_model.encoder_q.fc.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for images, labels in train_100_loader:\n",
        "        # print(images.shape)  # [batch_size, 3, 28, 28]\n",
        "        # break\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "\n",
        "        outputs = moco_model.encoder_q(images)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Fine-tuning Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmoVdLgr8pmL",
        "outputId": "0f4ee6ee-4292-41e6-e71b-c29833b08c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning Epoch 1, Loss: 2.4975180625915527\n",
            "Fine-tuning Epoch 2, Loss: 1.3721848726272583\n",
            "Fine-tuning Epoch 3, Loss: 1.735158920288086\n",
            "Fine-tuning Epoch 4, Loss: 0.657180666923523\n",
            "Fine-tuning Epoch 5, Loss: 0.8256850242614746\n",
            "Fine-tuning Epoch 6, Loss: 0.24648284912109375\n",
            "Fine-tuning Epoch 7, Loss: 0.3388679623603821\n",
            "Fine-tuning Epoch 8, Loss: 0.2687642574310303\n",
            "Fine-tuning Epoch 9, Loss: 0.18143151700496674\n",
            "Fine-tuning Epoch 10, Loss: 0.06478115171194077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_test_dataset = MNIST(root=DATASET_PATH, train=False, download=True, transform=labeled_transform)\n",
        "test_loader = DataLoader(MNIST_test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "mfO_voB1966H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(MNIST(root=DATASET_PATH, train=False, transform=base_transform), batch_size=batch_size)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = moco_model.encoder_q(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrSMJaBW9E7K",
        "outputId": "eab038b5-eaa7-4fe0-be07-cafb091a7db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 9.44%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}