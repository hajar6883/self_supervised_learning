{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "\n",
    "DATASET_PATH = \"./data\"\n",
    "random.seed(42)\n",
    "#Device\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation : Partionning & preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MNIST**\n",
    "\n",
    " Let's start by downloading the **MNIST** dataset: a very common and large database of grayscale images showing handwritten digits ranging from 0 to 9. It comprises 60,000 training images and 10,000 testing images of size 28x28.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to normalized Tensors in the range [0,1]\n",
    "\n",
    "transform = T.Compose([T.Pad(2) #to cope with the assumption about the \"same number of input pixels per image\", we choose the input dimension of 32x32 for all datasets. We thus resize all images (originally 28x28) using the padding function \"Pad\" (add 0 to the borders).\n",
    "                       , T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train_dataset = MNIST(root=DATASET_PATH, train= True, download=True, transform=transform)\n",
    "MNIST_test_dataset = MNIST(root=DATASET_PATH, train= False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Pad(padding=2, fill=0, padding_mode=constant)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Pad(padding=2, fill=0, padding_mode=constant)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_train_dataset, MNIST_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "NUM_IMAGES = 12\n",
    "MNIST_images = torch.stack([MNIST_train_dataset[np.random.randint(len(MNIST_train_dataset))][0] for idx in range(NUM_IMAGES)], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(MNIST_images, nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Image examples of the MNIST dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Mean: -0.794101893901825\n",
      "Batch Std: 0.5581037998199463\n",
      "Batch Min: -1.0\n",
      "Batch Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# use DataLoader to keep applied transformation when download the data..\n",
    "\n",
    "MNIST_train_loader = torch.utils.data.DataLoader(MNIST_train_dataset, batch_size=64, shuffle=True)\n",
    "MNIST_test_loader = torch.utils.data.DataLoader(MNIST_test_dataset, batch_size=64, shuffle=False)\n",
    "# help(MNIST_train_loader)\n",
    "#check stats :\n",
    "data_iter = iter(MNIST_train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "mean = images.mean()\n",
    "std = images.std()\n",
    "min_val = images.min()\n",
    "max_val = images.max()\n",
    "\n",
    "print(f'Batch Mean: {mean.item()}')\n",
    "print(f'Batch Std: {std.item()}')\n",
    "print(f'Batch Min: {min_val.item()}')\n",
    "print(f'Batch Max: {max_val.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = next(iter(MNIST_train_loader))\n",
    "print(train_images.shape) \n",
    "print(train_labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model Setup : extent with limited labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(MNIST_train_dataset))[:100]\n",
    "\n",
    "train_100= Subset(MNIST_train_dataset, indices)\n",
    "train_100_loader = DataLoader(train_100, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=\"same\")  \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=\"same\")\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)  \n",
    "        self.dp1 = nn.Dropout(p=0.25) \n",
    "        self.fc1 = nn.Linear(in_features=32 * 16 * 16, out_features=512)  \n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))     \n",
    "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 -> ReLU -> MaxPool\n",
    "        x = self.dp1(x)                 # Dropout1\n",
    "        x = torch.flatten(x, 1)        \n",
    "        x = F.relu(self.fc1(x))         \n",
    "        x = self.dp2(x)                 \n",
    "        x = self.fc2(x) #logits                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.0978\n",
      "Epoch [2/500], Loss: 0.0176\n",
      "Epoch [3/500], Loss: 0.0438\n",
      "Epoch [4/500], Loss: 0.0259\n",
      "Epoch [5/500], Loss: 0.1331\n",
      "Epoch [6/500], Loss: 0.0627\n",
      "Epoch [7/500], Loss: 0.0278\n",
      "Epoch [8/500], Loss: 0.0231\n",
      "Epoch [9/500], Loss: 0.0284\n",
      "Epoch [10/500], Loss: 0.0066\n",
      "Epoch [11/500], Loss: 0.0131\n",
      "Epoch [12/500], Loss: 0.0096\n",
      "Epoch [13/500], Loss: 0.0133\n",
      "Epoch [14/500], Loss: 0.0159\n",
      "Epoch [15/500], Loss: 0.0050\n",
      "Epoch [16/500], Loss: 0.0056\n",
      "Epoch [17/500], Loss: 0.0014\n",
      "Epoch [18/500], Loss: 0.0064\n",
      "Epoch [19/500], Loss: 0.0044\n",
      "Epoch [20/500], Loss: 0.0056\n",
      "Epoch [21/500], Loss: 0.0015\n",
      "Epoch [22/500], Loss: 0.0063\n",
      "Epoch [23/500], Loss: 0.0015\n",
      "Epoch [24/500], Loss: 0.0012\n",
      "Epoch [25/500], Loss: 0.0006\n",
      "Epoch [26/500], Loss: 0.0006\n",
      "Epoch [27/500], Loss: 0.0005\n",
      "Epoch [28/500], Loss: 0.0015\n",
      "Epoch [29/500], Loss: 0.0052\n",
      "Epoch [30/500], Loss: 0.0015\n",
      "Epoch [31/500], Loss: 0.0026\n",
      "Epoch [32/500], Loss: 0.0011\n",
      "Epoch [33/500], Loss: 0.0062\n",
      "Epoch [34/500], Loss: 0.0255\n",
      "Epoch [35/500], Loss: 0.0141\n",
      "Epoch [36/500], Loss: 0.0116\n",
      "Epoch [37/500], Loss: 0.0207\n",
      "Epoch [38/500], Loss: 0.0321\n",
      "Epoch [39/500], Loss: 0.0068\n",
      "Epoch [40/500], Loss: 0.0211\n",
      "Epoch [41/500], Loss: 0.0203\n",
      "Epoch [42/500], Loss: 0.0229\n",
      "Epoch [43/500], Loss: 0.0195\n",
      "Epoch [44/500], Loss: 0.1007\n",
      "Epoch [45/500], Loss: 0.0578\n",
      "Epoch [46/500], Loss: 0.0255\n",
      "Epoch [47/500], Loss: 0.0171\n",
      "Epoch [48/500], Loss: 0.0115\n",
      "Epoch [49/500], Loss: 0.0052\n",
      "Epoch [50/500], Loss: 0.0031\n",
      "Epoch [51/500], Loss: 0.0023\n",
      "Epoch [52/500], Loss: 0.0112\n",
      "Epoch [53/500], Loss: 0.0211\n",
      "Epoch [54/500], Loss: 0.0055\n",
      "Epoch [55/500], Loss: 0.0038\n",
      "Epoch [56/500], Loss: 0.0059\n",
      "Epoch [57/500], Loss: 0.0022\n",
      "Epoch [58/500], Loss: 0.0050\n",
      "Epoch [59/500], Loss: 0.0002\n",
      "Epoch [60/500], Loss: 0.0007\n",
      "Epoch [61/500], Loss: 0.0002\n",
      "Epoch [62/500], Loss: 0.0002\n",
      "Epoch [63/500], Loss: 0.0003\n",
      "Epoch [64/500], Loss: 0.0006\n",
      "Epoch [65/500], Loss: 0.0009\n",
      "Epoch [66/500], Loss: 0.0002\n",
      "Epoch [67/500], Loss: 0.0004\n",
      "Epoch [68/500], Loss: 0.0001\n",
      "Epoch [69/500], Loss: 0.0013\n",
      "Epoch [70/500], Loss: 0.0001\n",
      "Epoch [71/500], Loss: 0.0002\n",
      "Epoch [72/500], Loss: 0.0003\n",
      "Epoch [73/500], Loss: 0.0002\n",
      "Epoch [74/500], Loss: 0.0002\n",
      "Epoch [75/500], Loss: 0.0005\n",
      "Epoch [76/500], Loss: 0.0001\n",
      "Epoch [77/500], Loss: 0.0002\n",
      "Epoch [78/500], Loss: 0.0003\n",
      "Epoch [79/500], Loss: 0.0052\n",
      "Epoch [80/500], Loss: 0.0006\n",
      "Epoch [81/500], Loss: 0.0052\n",
      "Epoch [82/500], Loss: 0.0007\n",
      "Epoch [83/500], Loss: 0.0008\n",
      "Epoch [84/500], Loss: 0.0006\n",
      "Epoch [85/500], Loss: 0.0006\n",
      "Epoch [86/500], Loss: 0.0001\n",
      "Epoch [87/500], Loss: 0.0001\n",
      "Epoch [88/500], Loss: 0.0004\n",
      "Epoch [89/500], Loss: 0.0001\n",
      "Epoch [90/500], Loss: 0.0005\n",
      "Epoch [91/500], Loss: 0.0003\n",
      "Epoch [92/500], Loss: 0.0001\n",
      "Epoch [93/500], Loss: 0.0001\n",
      "Epoch [94/500], Loss: 0.0001\n",
      "Epoch [95/500], Loss: 0.0003\n",
      "Epoch [96/500], Loss: 0.0003\n",
      "Epoch [97/500], Loss: 0.0003\n",
      "Epoch [98/500], Loss: 0.0001\n",
      "Epoch [99/500], Loss: 0.0002\n",
      "Epoch [100/500], Loss: 0.0001\n",
      "Epoch [101/500], Loss: 0.0002\n",
      "Epoch [102/500], Loss: 0.0003\n",
      "Epoch [103/500], Loss: 0.0003\n",
      "Epoch [104/500], Loss: 0.0001\n",
      "Epoch [105/500], Loss: 0.0001\n",
      "Epoch [106/500], Loss: 0.0005\n",
      "Epoch [107/500], Loss: 0.0001\n",
      "Epoch [108/500], Loss: 0.0002\n",
      "Epoch [109/500], Loss: 0.0001\n",
      "Epoch [110/500], Loss: 0.0007\n",
      "Epoch [111/500], Loss: 0.0001\n",
      "Epoch [112/500], Loss: 0.0005\n",
      "Epoch [113/500], Loss: 0.0000\n",
      "Epoch [114/500], Loss: 0.0004\n",
      "Epoch [115/500], Loss: 0.0000\n",
      "Epoch [116/500], Loss: 0.0000\n",
      "Epoch [117/500], Loss: 0.0000\n",
      "Epoch [118/500], Loss: 0.0001\n",
      "Epoch [119/500], Loss: 0.0003\n",
      "Epoch [120/500], Loss: 0.0001\n",
      "Epoch [121/500], Loss: 0.0001\n",
      "Epoch [122/500], Loss: 0.0003\n",
      "Epoch [123/500], Loss: 0.0003\n",
      "Epoch [124/500], Loss: 0.0002\n",
      "Epoch [125/500], Loss: 0.0002\n",
      "Epoch [126/500], Loss: 0.0001\n",
      "Epoch [127/500], Loss: 0.0000\n",
      "Epoch [128/500], Loss: 0.0000\n",
      "Epoch [129/500], Loss: 0.0000\n",
      "Epoch [130/500], Loss: 0.0001\n",
      "Epoch [131/500], Loss: 0.0008\n",
      "Epoch [132/500], Loss: 0.0000\n",
      "Epoch [133/500], Loss: 0.0000\n",
      "Epoch [134/500], Loss: 0.0001\n",
      "Epoch [135/500], Loss: 0.0000\n",
      "Epoch [136/500], Loss: 0.0000\n",
      "Epoch [137/500], Loss: 0.0001\n",
      "Epoch [138/500], Loss: 0.0004\n",
      "Epoch [139/500], Loss: 0.0002\n",
      "Epoch [140/500], Loss: 0.0000\n",
      "Epoch [141/500], Loss: 0.0001\n",
      "Epoch [142/500], Loss: 0.0000\n",
      "Epoch [143/500], Loss: 0.0000\n",
      "Epoch [144/500], Loss: 0.0007\n",
      "Epoch [145/500], Loss: 0.0001\n",
      "Epoch [146/500], Loss: 0.0000\n",
      "Epoch [147/500], Loss: 0.0000\n",
      "Epoch [148/500], Loss: 0.0000\n",
      "Epoch [149/500], Loss: 0.0000\n",
      "Epoch [150/500], Loss: 0.0001\n",
      "Epoch [151/500], Loss: 0.0001\n",
      "Epoch [152/500], Loss: 0.0000\n",
      "Epoch [153/500], Loss: 0.0001\n",
      "Epoch [154/500], Loss: 0.0000\n",
      "Epoch [155/500], Loss: 0.0001\n",
      "Epoch [156/500], Loss: 0.0001\n",
      "Epoch [157/500], Loss: 0.0000\n",
      "Epoch [158/500], Loss: 0.0000\n",
      "Epoch [159/500], Loss: 0.0000\n",
      "Epoch [160/500], Loss: 0.0000\n",
      "Epoch [161/500], Loss: 0.0000\n",
      "Epoch [162/500], Loss: 0.0000\n",
      "Epoch [163/500], Loss: 0.0000\n",
      "Epoch [164/500], Loss: 0.0000\n",
      "Epoch [165/500], Loss: 0.0000\n",
      "Epoch [166/500], Loss: 0.0001\n",
      "Epoch [167/500], Loss: 0.0000\n",
      "Epoch [168/500], Loss: 0.0000\n",
      "Epoch [169/500], Loss: 0.0000\n",
      "Epoch [170/500], Loss: 0.0000\n",
      "Epoch [171/500], Loss: 0.0000\n",
      "Epoch [172/500], Loss: 0.0001\n",
      "Epoch [173/500], Loss: 0.0007\n",
      "Epoch [174/500], Loss: 0.0000\n",
      "Epoch [175/500], Loss: 0.0008\n",
      "Epoch [176/500], Loss: 0.0001\n",
      "Epoch [177/500], Loss: 0.0000\n",
      "Epoch [178/500], Loss: 0.0003\n",
      "Epoch [179/500], Loss: 0.0000\n",
      "Epoch [180/500], Loss: 0.0000\n",
      "Epoch [181/500], Loss: 0.0000\n",
      "Epoch [182/500], Loss: 0.0001\n",
      "Epoch [183/500], Loss: 0.0000\n",
      "Epoch [184/500], Loss: 0.0001\n",
      "Epoch [185/500], Loss: 0.0000\n",
      "Epoch [186/500], Loss: 0.0000\n",
      "Epoch [187/500], Loss: 0.0000\n",
      "Epoch [188/500], Loss: 0.0001\n",
      "Epoch [189/500], Loss: 0.0001\n",
      "Epoch [190/500], Loss: 0.0000\n",
      "Epoch [191/500], Loss: 0.0000\n",
      "Epoch [192/500], Loss: 0.0000\n",
      "Epoch [193/500], Loss: 0.0000\n",
      "Epoch [194/500], Loss: 0.0000\n",
      "Epoch [195/500], Loss: 0.0000\n",
      "Epoch [196/500], Loss: 0.0000\n",
      "Epoch [197/500], Loss: 0.0000\n",
      "Epoch [198/500], Loss: 0.0000\n",
      "Epoch [199/500], Loss: 0.0014\n",
      "Epoch [200/500], Loss: 0.0001\n",
      "Epoch [201/500], Loss: 0.1026\n",
      "Epoch [202/500], Loss: 0.0002\n",
      "Epoch [203/500], Loss: 0.0086\n",
      "Epoch [204/500], Loss: 0.0489\n",
      "Epoch [205/500], Loss: 0.0986\n",
      "Epoch [206/500], Loss: 0.0637\n",
      "Epoch [207/500], Loss: 0.0297\n",
      "Epoch [208/500], Loss: 0.1799\n",
      "Epoch [209/500], Loss: 0.1284\n",
      "Epoch [210/500], Loss: 0.0986\n",
      "Epoch [211/500], Loss: 0.0762\n",
      "Epoch [212/500], Loss: 0.0125\n",
      "Epoch [213/500], Loss: 0.0042\n",
      "Epoch [214/500], Loss: 0.0028\n",
      "Epoch [215/500], Loss: 0.0151\n",
      "Epoch [216/500], Loss: 0.0009\n",
      "Epoch [217/500], Loss: 0.0009\n",
      "Epoch [218/500], Loss: 0.0028\n",
      "Epoch [219/500], Loss: 0.0256\n",
      "Epoch [220/500], Loss: 0.0096\n",
      "Epoch [221/500], Loss: 0.0388\n",
      "Epoch [222/500], Loss: 0.0013\n",
      "Epoch [223/500], Loss: 0.0031\n",
      "Epoch [224/500], Loss: 0.0010\n",
      "Epoch [225/500], Loss: 0.0014\n",
      "Epoch [226/500], Loss: 0.0008\n",
      "Epoch [227/500], Loss: 0.0007\n",
      "Epoch [228/500], Loss: 0.0005\n",
      "Epoch [229/500], Loss: 0.0144\n",
      "Epoch [230/500], Loss: 0.0132\n",
      "Epoch [231/500], Loss: 0.0003\n",
      "Epoch [232/500], Loss: 0.0027\n",
      "Epoch [233/500], Loss: 0.0003\n",
      "Epoch [234/500], Loss: 0.0021\n",
      "Epoch [235/500], Loss: 0.0020\n",
      "Epoch [236/500], Loss: 0.0004\n",
      "Epoch [237/500], Loss: 0.0002\n",
      "Epoch [238/500], Loss: 0.0001\n",
      "Epoch [239/500], Loss: 0.0001\n",
      "Epoch [240/500], Loss: 0.0000\n",
      "Epoch [241/500], Loss: 0.0001\n",
      "Epoch [242/500], Loss: 0.0000\n",
      "Epoch [243/500], Loss: 0.0001\n",
      "Epoch [244/500], Loss: 0.0001\n",
      "Epoch [245/500], Loss: 0.0000\n",
      "Epoch [246/500], Loss: 0.0059\n",
      "Epoch [247/500], Loss: 0.0000\n",
      "Epoch [248/500], Loss: 0.0001\n",
      "Epoch [249/500], Loss: 0.0077\n",
      "Epoch [250/500], Loss: 0.0058\n",
      "Epoch [251/500], Loss: 0.0042\n",
      "Epoch [252/500], Loss: 0.0003\n",
      "Epoch [253/500], Loss: 0.0004\n",
      "Epoch [254/500], Loss: 0.0028\n",
      "Epoch [255/500], Loss: 0.0001\n",
      "Epoch [256/500], Loss: 0.0030\n",
      "Epoch [257/500], Loss: 0.0000\n",
      "Epoch [258/500], Loss: 0.0004\n",
      "Epoch [259/500], Loss: 0.0005\n",
      "Epoch [260/500], Loss: 0.0012\n",
      "Epoch [261/500], Loss: 0.0000\n",
      "Epoch [262/500], Loss: 0.0000\n",
      "Epoch [263/500], Loss: 0.0005\n",
      "Epoch [264/500], Loss: 0.0001\n",
      "Epoch [265/500], Loss: 0.0003\n",
      "Epoch [266/500], Loss: 0.0000\n",
      "Epoch [267/500], Loss: 0.0000\n",
      "Epoch [268/500], Loss: 0.0001\n",
      "Epoch [269/500], Loss: 0.0000\n",
      "Epoch [270/500], Loss: 0.0000\n",
      "Epoch [271/500], Loss: 0.0000\n",
      "Epoch [272/500], Loss: 0.0000\n",
      "Epoch [273/500], Loss: 0.0000\n",
      "Epoch [274/500], Loss: 0.0008\n",
      "Epoch [275/500], Loss: 0.0000\n",
      "Epoch [276/500], Loss: 0.0000\n",
      "Epoch [277/500], Loss: 0.0000\n",
      "Epoch [278/500], Loss: 0.0000\n",
      "Epoch [279/500], Loss: 0.0000\n",
      "Epoch [280/500], Loss: 0.0000\n",
      "Epoch [281/500], Loss: 0.0000\n",
      "Epoch [282/500], Loss: 0.0000\n",
      "Epoch [283/500], Loss: 0.0000\n",
      "Epoch [284/500], Loss: 0.0000\n",
      "Epoch [285/500], Loss: 0.0000\n",
      "Epoch [286/500], Loss: 0.0000\n",
      "Epoch [287/500], Loss: 0.0000\n",
      "Epoch [288/500], Loss: 0.0000\n",
      "Epoch [289/500], Loss: 0.0000\n",
      "Epoch [290/500], Loss: 0.0000\n",
      "Epoch [291/500], Loss: 0.0000\n",
      "Epoch [292/500], Loss: 0.0000\n",
      "Epoch [293/500], Loss: 0.0000\n",
      "Epoch [294/500], Loss: 0.0000\n",
      "Epoch [295/500], Loss: 0.0000\n",
      "Epoch [296/500], Loss: 0.0000\n",
      "Epoch [297/500], Loss: 0.0000\n",
      "Epoch [298/500], Loss: 0.0005\n",
      "Epoch [299/500], Loss: 0.0000\n",
      "Epoch [300/500], Loss: 0.0001\n",
      "Epoch [301/500], Loss: 0.0000\n",
      "Epoch [302/500], Loss: 0.0000\n",
      "Epoch [303/500], Loss: 0.0060\n",
      "Epoch [304/500], Loss: 0.0000\n",
      "Epoch [305/500], Loss: 0.0057\n",
      "Epoch [306/500], Loss: 0.0002\n",
      "Epoch [307/500], Loss: 0.0319\n",
      "Epoch [308/500], Loss: 0.0000\n",
      "Epoch [309/500], Loss: 0.0055\n",
      "Epoch [310/500], Loss: 0.0275\n",
      "Epoch [311/500], Loss: 0.0036\n",
      "Epoch [312/500], Loss: 0.1093\n",
      "Epoch [313/500], Loss: 0.0028\n",
      "Epoch [314/500], Loss: 0.0479\n",
      "Epoch [315/500], Loss: 0.0006\n",
      "Epoch [316/500], Loss: 0.0127\n",
      "Epoch [317/500], Loss: 0.0008\n",
      "Epoch [318/500], Loss: 0.0069\n",
      "Epoch [319/500], Loss: 0.0000\n",
      "Epoch [320/500], Loss: 0.0000\n",
      "Epoch [321/500], Loss: 0.0017\n",
      "Epoch [322/500], Loss: 0.0000\n",
      "Epoch [323/500], Loss: 0.0097\n",
      "Epoch [324/500], Loss: 0.0001\n",
      "Epoch [325/500], Loss: 0.0034\n",
      "Epoch [326/500], Loss: 0.0001\n",
      "Epoch [327/500], Loss: 0.0001\n",
      "Epoch [328/500], Loss: 0.0001\n",
      "Epoch [329/500], Loss: 0.0287\n",
      "Epoch [330/500], Loss: 0.0609\n",
      "Epoch [331/500], Loss: 0.0003\n",
      "Epoch [332/500], Loss: 0.0281\n",
      "Epoch [333/500], Loss: 0.0017\n",
      "Epoch [334/500], Loss: 0.0011\n",
      "Epoch [335/500], Loss: 0.0002\n",
      "Epoch [336/500], Loss: 0.0002\n",
      "Epoch [337/500], Loss: 0.0772\n",
      "Epoch [338/500], Loss: 0.0048\n",
      "Epoch [339/500], Loss: 0.0014\n",
      "Epoch [340/500], Loss: 0.0045\n",
      "Epoch [341/500], Loss: 0.0002\n",
      "Epoch [342/500], Loss: 0.0036\n",
      "Epoch [343/500], Loss: 0.0001\n",
      "Epoch [344/500], Loss: 0.0351\n",
      "Epoch [345/500], Loss: 0.0201\n",
      "Epoch [346/500], Loss: 0.0023\n",
      "Epoch [347/500], Loss: 0.0424\n",
      "Epoch [348/500], Loss: 0.0012\n",
      "Epoch [349/500], Loss: 0.0015\n",
      "Epoch [350/500], Loss: 0.0005\n",
      "Epoch [351/500], Loss: 0.0012\n",
      "Epoch [352/500], Loss: 0.0001\n",
      "Epoch [353/500], Loss: 0.0002\n",
      "Epoch [354/500], Loss: 0.0056\n",
      "Epoch [355/500], Loss: 0.0025\n",
      "Epoch [356/500], Loss: 0.0001\n",
      "Epoch [357/500], Loss: 0.0039\n",
      "Epoch [358/500], Loss: 0.0001\n",
      "Epoch [359/500], Loss: 0.0000\n",
      "Epoch [360/500], Loss: 0.0001\n",
      "Epoch [361/500], Loss: 0.0001\n",
      "Epoch [362/500], Loss: 0.0002\n",
      "Epoch [363/500], Loss: 0.0001\n",
      "Epoch [364/500], Loss: 0.0000\n",
      "Epoch [365/500], Loss: 0.0000\n",
      "Epoch [366/500], Loss: 0.0000\n",
      "Epoch [367/500], Loss: 0.0013\n",
      "Epoch [368/500], Loss: 0.0000\n",
      "Epoch [369/500], Loss: 0.0000\n",
      "Epoch [370/500], Loss: 0.0000\n",
      "Epoch [371/500], Loss: 0.0000\n",
      "Epoch [372/500], Loss: 0.0000\n",
      "Epoch [373/500], Loss: 0.0000\n",
      "Epoch [374/500], Loss: 0.0000\n",
      "Epoch [375/500], Loss: 0.0000\n",
      "Epoch [376/500], Loss: 0.0018\n",
      "Epoch [377/500], Loss: 0.0000\n",
      "Epoch [378/500], Loss: 0.0001\n",
      "Epoch [379/500], Loss: 0.0000\n",
      "Epoch [380/500], Loss: 0.0000\n",
      "Epoch [381/500], Loss: 0.0001\n",
      "Epoch [382/500], Loss: 0.0000\n",
      "Epoch [383/500], Loss: 0.0000\n",
      "Epoch [384/500], Loss: 0.0000\n",
      "Epoch [385/500], Loss: 0.0001\n",
      "Epoch [386/500], Loss: 0.0000\n",
      "Epoch [387/500], Loss: 0.0000\n",
      "Epoch [388/500], Loss: 0.0000\n",
      "Epoch [389/500], Loss: 0.0000\n",
      "Epoch [390/500], Loss: 0.0000\n",
      "Epoch [391/500], Loss: 0.0000\n",
      "Epoch [392/500], Loss: 0.0000\n",
      "Epoch [393/500], Loss: 0.0000\n",
      "Epoch [394/500], Loss: 0.0000\n",
      "Epoch [395/500], Loss: 0.0000\n",
      "Epoch [396/500], Loss: 0.0000\n",
      "Epoch [397/500], Loss: 0.0001\n",
      "Epoch [398/500], Loss: 0.0000\n",
      "Epoch [399/500], Loss: 0.0000\n",
      "Epoch [400/500], Loss: 0.0000\n",
      "Epoch [401/500], Loss: 0.0000\n",
      "Epoch [402/500], Loss: 0.0001\n",
      "Epoch [403/500], Loss: 0.0000\n",
      "Epoch [404/500], Loss: 0.0000\n",
      "Epoch [405/500], Loss: 0.0002\n",
      "Epoch [406/500], Loss: 0.0000\n",
      "Epoch [407/500], Loss: 0.0000\n",
      "Epoch [408/500], Loss: 0.0000\n",
      "Epoch [409/500], Loss: 0.0000\n",
      "Epoch [410/500], Loss: 0.0000\n",
      "Epoch [411/500], Loss: 0.0000\n",
      "Epoch [412/500], Loss: 0.0000\n",
      "Epoch [413/500], Loss: 0.0020\n",
      "Epoch [414/500], Loss: 0.0001\n",
      "Epoch [415/500], Loss: 0.0000\n",
      "Epoch [416/500], Loss: 0.0000\n",
      "Epoch [417/500], Loss: 0.0000\n",
      "Epoch [418/500], Loss: 0.0010\n",
      "Epoch [419/500], Loss: 0.0000\n",
      "Epoch [420/500], Loss: 0.0000\n",
      "Epoch [421/500], Loss: 0.0000\n",
      "Epoch [422/500], Loss: 0.0000\n",
      "Epoch [423/500], Loss: 0.0000\n",
      "Epoch [424/500], Loss: 0.0019\n",
      "Epoch [425/500], Loss: 0.0000\n",
      "Epoch [426/500], Loss: 0.0000\n",
      "Epoch [427/500], Loss: 0.0000\n",
      "Epoch [428/500], Loss: 0.0000\n",
      "Epoch [429/500], Loss: 0.0000\n",
      "Epoch [430/500], Loss: 0.0000\n",
      "Epoch [431/500], Loss: 0.0000\n",
      "Epoch [432/500], Loss: 0.0000\n",
      "Epoch [433/500], Loss: 0.0000\n",
      "Epoch [434/500], Loss: 0.0000\n",
      "Epoch [435/500], Loss: 0.0000\n",
      "Epoch [436/500], Loss: 0.0000\n",
      "Epoch [437/500], Loss: 0.0000\n",
      "Epoch [438/500], Loss: 0.0000\n",
      "Epoch [439/500], Loss: 0.0000\n",
      "Epoch [440/500], Loss: 0.0001\n",
      "Epoch [441/500], Loss: 0.0000\n",
      "Epoch [442/500], Loss: 0.0002\n",
      "Epoch [443/500], Loss: 0.0001\n",
      "Epoch [444/500], Loss: 0.0000\n",
      "Epoch [445/500], Loss: 0.0000\n",
      "Epoch [446/500], Loss: 0.0000\n",
      "Epoch [447/500], Loss: 0.0000\n",
      "Epoch [448/500], Loss: 0.0000\n",
      "Epoch [449/500], Loss: 0.0000\n",
      "Epoch [450/500], Loss: 0.0000\n",
      "Epoch [451/500], Loss: 0.0000\n",
      "Epoch [452/500], Loss: 0.0000\n",
      "Epoch [453/500], Loss: 0.0000\n",
      "Epoch [454/500], Loss: 0.0159\n",
      "Epoch [455/500], Loss: 0.0000\n",
      "Epoch [456/500], Loss: 0.0000\n",
      "Epoch [457/500], Loss: 0.0000\n",
      "Epoch [458/500], Loss: 0.0000\n",
      "Epoch [459/500], Loss: 0.0000\n",
      "Epoch [460/500], Loss: 0.0001\n",
      "Epoch [461/500], Loss: 0.0000\n",
      "Epoch [462/500], Loss: 0.0236\n",
      "Epoch [463/500], Loss: 0.0516\n",
      "Epoch [464/500], Loss: 0.0196\n",
      "Epoch [465/500], Loss: 0.0000\n",
      "Epoch [466/500], Loss: 0.0487\n",
      "Epoch [467/500], Loss: 0.0000\n",
      "Epoch [468/500], Loss: 0.0002\n",
      "Epoch [469/500], Loss: 0.0000\n",
      "Epoch [470/500], Loss: 0.0000\n",
      "Epoch [471/500], Loss: 0.0011\n",
      "Epoch [472/500], Loss: 0.0000\n",
      "Epoch [473/500], Loss: 0.0000\n",
      "Epoch [474/500], Loss: 0.0249\n",
      "Epoch [475/500], Loss: 0.0001\n",
      "Epoch [476/500], Loss: 0.0000\n",
      "Epoch [477/500], Loss: 0.0001\n",
      "Epoch [478/500], Loss: 0.0000\n",
      "Epoch [479/500], Loss: 0.0000\n",
      "Epoch [480/500], Loss: 0.0000\n",
      "Epoch [481/500], Loss: 0.0001\n",
      "Epoch [482/500], Loss: 0.0009\n",
      "Epoch [483/500], Loss: 0.0000\n",
      "Epoch [484/500], Loss: 0.0000\n",
      "Epoch [485/500], Loss: 0.0132\n",
      "Epoch [486/500], Loss: 0.0000\n",
      "Epoch [487/500], Loss: 0.0863\n",
      "Epoch [488/500], Loss: 0.0001\n",
      "Epoch [489/500], Loss: 0.0001\n",
      "Epoch [490/500], Loss: 0.0049\n",
      "Epoch [491/500], Loss: 0.0001\n",
      "Epoch [492/500], Loss: 0.0001\n",
      "Epoch [493/500], Loss: 0.0001\n",
      "Epoch [494/500], Loss: 0.0001\n",
      "Epoch [495/500], Loss: 0.0002\n",
      "Epoch [496/500], Loss: 0.0000\n",
      "Epoch [497/500], Loss: 0.0002\n",
      "Epoch [498/500], Loss: 0.0000\n",
      "Epoch [499/500], Loss: 0.0000\n",
      "Epoch [500/500], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "model.train() \n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_100_loader:\n",
    "        optimizer.zero_grad()          \n",
    "        outputs = model(images)        \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()                \n",
    "        optimizer.step()              \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_100_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 81.92%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in MNIST_test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
