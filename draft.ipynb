{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## torch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Subset , random_split\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "\n",
    "DATASET_PATH = \"./data\"\n",
    "random.seed(42)\n",
    "#Device\n",
    "# device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from files.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation : Partionning & preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MNIST**\n",
    "\n",
    " Let's start by downloading the **MNIST** dataset: a very common and large database of grayscale images showing handwritten digits ranging from 0 to 9. It comprises 60,000 training images and 10,000 testing images of size 28x28.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to normalized Tensors in the range [0,1]\n",
    "\n",
    "transform = T.Compose([T.Pad(2) #to cope with the assumption about the \"same number of input pixels per image\", we choose the input dimension of 32x32 for all datasets. We thus resize all images (originally 28x28) using the padding function \"Pad\" (add 0 to the borders).\n",
    "                       , T.ToTensor(), T.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_train_dataset = MNIST(root=DATASET_PATH, train= True, download=True, transform=transform)\n",
    "MNIST_test_dataset = MNIST(root=DATASET_PATH, train= False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Pad(padding=2, fill=0, padding_mode=constant)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Pad(padding=2, fill=0, padding_mode=constant)\n",
       "                ToTensor()\n",
       "                Normalize(mean=(0.5,), std=(0.5,))\n",
       "            ))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_train_dataset, MNIST_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some examples\n",
    "NUM_IMAGES = 12\n",
    "MNIST_images = torch.stack([MNIST_train_dataset[np.random.randint(len(MNIST_train_dataset))][0] for idx in range(NUM_IMAGES)], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(MNIST_images, nrow=6, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Image examples of the MNIST dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Mean: -0.7804680466651917\n",
      "Batch Std: 0.5762251615524292\n",
      "Batch Min: -1.0\n",
      "Batch Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# use DataLoader to keep applied transformation when download the data..\n",
    "\n",
    "MNIST_train_loader = torch.utils.data.DataLoader(MNIST_train_dataset, batch_size=64, shuffle=True)\n",
    "MNIST_test_loader = torch.utils.data.DataLoader(MNIST_test_dataset, batch_size=64, shuffle=False)\n",
    "# help(MNIST_train_loader)\n",
    "#check stats :\n",
    "data_iter = iter(MNIST_train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "mean = images.mean()\n",
    "std = images.std()\n",
    "min_val = images.min()\n",
    "max_val = images.max()\n",
    "\n",
    "print(f'Batch Mean: {mean.item()}')\n",
    "print(f'Batch Std: {std.item()}')\n",
    "print(f'Batch Min: {min_val.item()}')\n",
    "print(f'Batch Max: {max_val.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = next(iter(MNIST_train_loader))\n",
    "print(train_images.shape) \n",
    "print(train_labels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model Setup : extent with limited labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(len(MNIST_train_dataset))[:100]\n",
    "\n",
    "train_100= Subset(MNIST_train_dataset, indices)\n",
    "train_100_loader = DataLoader(train_100, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 32]), 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_100[0]  \n",
    "image.shape, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Basic_CNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 3.1209\n",
      "Epoch [2/10], Loss: 2.0246\n",
      "Epoch [3/10], Loss: 1.6912\n",
      "Epoch [4/10], Loss: 1.2193\n",
      "Epoch [5/10], Loss: 0.9272\n",
      "Epoch [6/10], Loss: 0.7110\n",
      "Epoch [7/10], Loss: 0.5366\n",
      "Epoch [8/10], Loss: 0.4204\n",
      "Epoch [9/10], Loss: 0.3738\n",
      "Epoch [10/10], Loss: 0.2870\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.train() \n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_100_loader:\n",
    "        optimizer.zero_grad()          \n",
    "        outputs = model(images)        \n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()                \n",
    "        optimizer.step()              \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_100_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set (10K): 66.29%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in MNIST_test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the test set (10K): {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MoCo was implemented on RGB ImageNet data with and ResNet encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adapting the input layer to handle 28x28 grayscale images (instead of the 224x224 RGB images typically used with ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_MoCo = T.Compose([\n",
    "    T.Resize((32, 32)),  \n",
    "    T.Grayscale(3),      # duplicate channels to simulate RGB\n",
    "    T.RandomApply([\n",
    "        T.RandomRotation(10),\n",
    "        T.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "    ]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # std ImageNet normalization\n",
    "])\n",
    "\n",
    "train_MoCo = MNIST(root=DATASET_PATH, train=True, download=True, transform=transform_MoCo)\n",
    "test_MoCo= MNIST(root=DATASET_PATH, train= False, download=True, transform=transform_MoCo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* modify MoCo loader to handle our data\n",
    "* configuration (explore light encoder beside resnet(mnist is too simple than imageNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "workers = 4\n",
    "\n",
    "MoCo_train_loader = DataLoader(train_MoCo, batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
    "MoCo_test_loader = DataLoader(test_MoCo, batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  \u001b[34m__pycache__\u001b[m\u001b[m/ \u001b[34mdata\u001b[m\u001b[m/        draft.ipynb  \u001b[34mfiles\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/grace/Desktop/M2/deep_learning/self_supervised_learning\n",
      "Python path: ['/Users/grace/Desktop/M2/deep_learning/self_supervised_learning', '/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/grace/Library/Python/3.11/lib/python/site-packages', '/opt/homebrew/lib/python3.11/site-packages', '/opt/homebrew/lib/python3.11/site-packages/gpg-1.23.1-py3.11-macosx-12-arm64.egg', '/Users/grace/Desktop/M2', '/Users/grace/Desktop/M2/deep_learning/self_supervised_learning/moco', '/Users/grace/Desktop/M2/deep_learning/moco', '/Users/grace/Desktop/M2/deep_learning/moco/moco', '/Users/grace/Desktop/M2/deep_learning']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.abspath('.') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "print(\"Python path:\", sys.path)\n",
    "\n",
    "from moco.builder import MoCo\n",
    "from moco.loader import TwoCropsTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AlexNet', 'AlexNet_Weights', 'ConvNeXt', 'ConvNeXt_Base_Weights', 'ConvNeXt_Large_Weights', 'ConvNeXt_Small_Weights', 'ConvNeXt_Tiny_Weights', 'DenseNet', 'DenseNet121_Weights', 'DenseNet161_Weights', 'DenseNet169_Weights', 'DenseNet201_Weights', 'EfficientNet', 'EfficientNet_B0_Weights', 'EfficientNet_B1_Weights', 'EfficientNet_B2_Weights', 'EfficientNet_B3_Weights', 'EfficientNet_B4_Weights', 'EfficientNet_B5_Weights', 'EfficientNet_B6_Weights', 'EfficientNet_B7_Weights', 'EfficientNet_V2_L_Weights', 'EfficientNet_V2_M_Weights', 'EfficientNet_V2_S_Weights', 'GoogLeNet', 'GoogLeNetOutputs', 'GoogLeNet_Weights', 'Inception3', 'InceptionOutputs', 'Inception_V3_Weights', 'MNASNet', 'MNASNet0_5_Weights', 'MNASNet0_75_Weights', 'MNASNet1_0_Weights', 'MNASNet1_3_Weights', 'MaxVit', 'MaxVit_T_Weights', 'MobileNetV2', 'MobileNetV3', 'MobileNet_V2_Weights', 'MobileNet_V3_Large_Weights', 'MobileNet_V3_Small_Weights', 'RegNet', 'RegNet_X_16GF_Weights', 'RegNet_X_1_6GF_Weights', 'RegNet_X_32GF_Weights', 'RegNet_X_3_2GF_Weights', 'RegNet_X_400MF_Weights', 'RegNet_X_800MF_Weights', 'RegNet_X_8GF_Weights', 'RegNet_Y_128GF_Weights', 'RegNet_Y_16GF_Weights', 'RegNet_Y_1_6GF_Weights', 'RegNet_Y_32GF_Weights', 'RegNet_Y_3_2GF_Weights', 'RegNet_Y_400MF_Weights', 'RegNet_Y_800MF_Weights', 'RegNet_Y_8GF_Weights', 'ResNeXt101_32X8D_Weights', 'ResNeXt101_64X4D_Weights', 'ResNeXt50_32X4D_Weights', 'ResNet', 'ResNet101_Weights', 'ResNet152_Weights', 'ResNet18_Weights', 'ResNet34_Weights', 'ResNet50_Weights', 'ShuffleNetV2', 'ShuffleNet_V2_X0_5_Weights', 'ShuffleNet_V2_X1_0_Weights', 'ShuffleNet_V2_X1_5_Weights', 'ShuffleNet_V2_X2_0_Weights', 'SqueezeNet', 'SqueezeNet1_0_Weights', 'SqueezeNet1_1_Weights', 'SwinTransformer', 'Swin_B_Weights', 'Swin_S_Weights', 'Swin_T_Weights', 'Swin_V2_B_Weights', 'Swin_V2_S_Weights', 'Swin_V2_T_Weights', 'VGG', 'VGG11_BN_Weights', 'VGG11_Weights', 'VGG13_BN_Weights', 'VGG13_Weights', 'VGG16_BN_Weights', 'VGG16_Weights', 'VGG19_BN_Weights', 'VGG19_Weights', 'ViT_B_16_Weights', 'ViT_B_32_Weights', 'ViT_H_14_Weights', 'ViT_L_16_Weights', 'ViT_L_32_Weights', 'VisionTransformer', 'Weights', 'WeightsEnum', 'Wide_ResNet101_2_Weights', 'Wide_ResNet50_2_Weights', '_GoogLeNetOutputs', '_InceptionOutputs', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_api', '_meta', '_utils', 'alexnet', 'convnext', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'detection', 'efficientnet', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'get_model', 'get_model_builder', 'get_model_weights', 'get_weight', 'googlenet', 'inception', 'inception_v3', 'list_models', 'maxvit', 'maxvit_t', 'mnasnet', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'mobilenetv2', 'mobilenetv3', 'optical_flow', 'quantization', 'regnet', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'segmentation', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'shufflenetv2', 'squeezenet', 'squeezenet1_0', 'squeezenet1_1', 'swin_b', 'swin_s', 'swin_t', 'swin_transformer', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'video', 'vision_transformer', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n"
     ]
    }
   ],
   "source": [
    "print(dir(models))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoCo(\n",
    "    base_encoder=models.resnet18,  \n",
    "    dim=128,                       \n",
    "    K=4096,                        \n",
    "    m=0.99,                        \n",
    "    T=0.07                         \n",
    ")\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "def train(model, data_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for images, _ in data_loader:\n",
    "            images = images.cuda()\n",
    "            output, target = model(images)  \n",
    "            loss = criterion(output, target)  \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = total = 0\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the model on test images: {100 * correct / total}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMoCo_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m----> 7\u001b[0m         images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         output, target \u001b[38;5;241m=\u001b[39m model(images)  \n\u001b[1;32m      9\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output, target)  \n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "train(model, MoCo_train_loader, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, MoCo_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
